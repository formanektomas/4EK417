---
title: "Generalized Additive Models (GAMs)"
output: html_document
---

```{r setup, include=T,warning=FALSE,message=FALSE}
library(interp)
library(ggplot2)
library(ISLR)
library(splines)
library(gam)
Wage <- ISLR::Wage
str(Wage)
```


GAMs extend multivariate LRMs by allowing non-linear functions & smoothers in each variable, while maintaining additivity (and easy interpretation for each regressor).

+ Individual $f_j$ in GAMs can be very flexible -- we do not have to manually try different transformations for each regressor.  

+ Non-linear fits can produce more accurate predictions.  



$$
y_i = \alpha + \, f_1(x_{i1}) + \, f_2(x_{i2}) + \cdots + \, f_p(x_{ip}) + u_i
$$ 

where each $f_j(x_{ij})$ represents a convenient function of $x$: smoothing spline, natural spline, local regression,  polynomial function, piecewise constant, etc.


--- 


## GAM & Natural splines 

+ As a special case, GAMs with natural splines can be estimated by OLS (no backcasting is necessary here).  

Consider the following example: 

$$
\texttt{Wage} ~ \leftarrow ~ f_1(\texttt{year}) + f_2( \texttt{age}) + f_3(\texttt{education}) + u
$$

where $f_1$ and $f_2$ are *natural splines* and $f_3$ is a step function. 

```{r, warning=F}
# note the syntax of ns(), e.g. we use ns(year, df=1) for linear func.
gam1 <- lm(wage~ns(year,df=4)+ns(age,df=5)+education, data=Wage) 
summary(gam1)
# Show  marginal effects (link scale) 
# - centered about the GAM constant term (mean of depvar)
par(mfrow=c(1,3))
gam::plot.Gam(gam1, se=T, col="red")
par(mfrow=c(1,1))
```

Plot interpretation:

+ As we hold $\texttt{age}$ and $\texttt{education}$ fixed, $\texttt{wage}$ increases slightly with $\texttt{year}$.  

+ If we fix $\texttt{year}$ and $\texttt{education}$, $\texttt{wage}$ tends to be highest for intermediate values of  $\texttt{age}$ and lowest for the very young and very old workers.  

--- 

## GAM models using the `{gam}` package:

* `gam(y ~ s(x1,4) + lo(x2) + Factor, data=Mydata)`

#### `gam::gam()` uses smoothing splines and local regression, default values and syntax shown:

* `s(x1, df=4)`
    + `df`: target equivalent degrees of freedom, used as a smoothing parameter,
    + `df=1` implying a linear fit

*  `lo(x2, span=0.5, degree=1)`   
    + `span` defines the number of observations in a neighborhood,
    + `degree` of local polynomial, either 1 or 2.

* For a categorial variable (Factor), a step function is produced.


---


## GAM & Smoothing splines 

+ With GAM & smoothing splines, we do not use an expansion of basis functions for estimation (i.e. constituent elements used in some matrix of regressors $\mathbf{X}$).  

+ Instead, we fit all $p$ functions "simultaneously", using a **backfitting algorithm**:

1. Initialize: $\hat{\alpha}=\frac{1}{n} \sum_{i=1}^n y_i~~\text{and}~~\hat{f}_j \equiv 0,~~\forall i,j.$ 

2. Cycle: $j = 1,2,\dots,p,1,2,\dots,p,\dots$  

    a. $\hat{f}_j~\leftarrow ~ \mathcal{S}_j \left[ \left\lbrace y_i - \hat{\alpha} - \sum_{k \neq j} \hat{f}_k (x_{ik}) \right\rbrace_1^n \right]~~~$ (backfitting step)  
    
    b. $\hat{f}_j~\leftarrow ~ \hat{f}_j - \frac{1}{n} \sum_{i-1}^n \hat{f}_j (x_{ij}) ~~~$ (mean centering of estimated function)
    

+ Without restrictions in Step 1, solution is non-unique -- constant $\alpha$ is non-identifiable as we can add/subtract any constant to each of the $f_j$ functions. This is solved in Step 1 (i.e. by setting $\hat{\alpha} = \text{mean}(y_i)$ and $\hat{f}_j \equiv 0 $). Note that this setting does not change troughout the backfitting estimation.  

+ Step 2 (a) applies a smoothing spline $\mathcal{S}_j$ to the $X_j$ regressor while fixing all other $\hat{f}_k$ at their current estimates when computing the $\left\lbrace y_i - \hat{\alpha} - \sum_{k \neq j} \hat{f}_k (x_{ik}) \right\rbrace_1^n$ term.  

+ Step 2 (b) is technical -- it adjusts for rounding errors in the algorithm (in theory, fit to a mean-zero response has mean zero).


--- 

#### Empirical example (contnd.)


$$
\texttt{Wage} ~ \leftarrow ~ f_1(\texttt{year}) + f_2( \texttt{age}) + f_3(\texttt{education}) + u
$$

where $f_1$ and $f_2$ are *smoothing splines* and $f_3$ is a step function. 


```{r, warning=F}
gam2 <- gam(wage~s(year,4)+s(age,5)+education, data=Wage) # target dfs chosen ad-hoc
par(mfrow=c(1,3))
plot(gam2, se=T, col="darkgreen") # syntax simplified since gam2 is a gam object
par(mfrow=c(1,1))
(sum.gam <- summary(gam2))
# 
# Test for significance of different constituent elements of the model
sum.gam$parametric.anova
#
# Test H_0 of linear relationship against H_1 of non-linear relationship
sum.gam$anova
```


+ Given the results of diagnostic tests, we drop the smoothing spline for $\texttt{year}$ and use a linear function instead: 


```{r, warning=F}
gam3 <- gam(wage~year+s(age,5)+education, data=Wage)
par(mfrow=c(1,3))
plot(gam3, se=T, col="blue")
par(mfrow=c(1,1))
summary(gam3)
# 
# ANOVA
anova(gam3,gam2,test="F")
```

+ We can see that the simpler model describes variability in the dependent variable equally well (at all reasonable significance levels).  


---  


## Predictions from a GAM model

+ A fitted GAM model can be used for predictions (in-sample fitted values as well as out-of-sample predicitons)

+ Fitted values (in-sample predictions) example:  

```{r, warning=F}
Gam.pred <- predict(gam3, se.fit = T)
ggplot(Wage, aes(x = Wage$wage, y = Gam.pred$fit) ) +
  geom_point(color="darkgreen")+
  ylim(0,320) +
  xlim(0,320) +
  coord_fixed() + # 1:1 x/y aspect ratio
  geom_segment(  aes(x=0, y=0, xend=320, yend=320), linewidth = 0.7, color='red', linetype = "dotted")+
  labs(title = "Actual vs fitted wages") +
  theme_bw()
```


--- 


## GAM: a combination of splines and local regression

+ We can easily combine different types of smoothers in a GAM:

```{r, warning=F}
gam4 <- gam(wage~s(year,df=2)+lo(age,span = 0.4, degree = 2)+education, data=Wage)
par(mfrow=c(1,3))
plot(gam4, se=T, col="blue") 
par(mfrow=c(1,1))
summary(gam4)
```


---

**Quick exercise**  

+ Interpret the above diagnostic tests in `summary(gam4)` and make amendments the the `gam4` specification as necessary.



--- 

## GAM & interaction elements

+ Interaction between $\texttt{age}$ and $\texttt{year}$ can be accounted for as follows 


```{r, warning=F}
gam5 <- gam(wage~lo(age,year, span = 0.4, degree = 1)+education, data=Wage)
summary(gam5)

```


+ The interaction term can be visualized as follows (3D plot repeated for perspective from both axes):  

```{r, echo=F, warning=F}
library(akima)
par(mfrow=c(1,2))
plot(gam5)
gam5b <- gam(wage~lo(year,age,span = 0.4)+education, data=Wage)
plot(gam5b)
par(mfrow=c(1,1))
```

---

## GAMs for binary dependent variable

+ GAM models can be used with LDVs as well. 

+ A simple logit example follows - our binary variable equals 1 (succes) if `wage > 250`.


```{r, warning=F}
gam6 <- gam(I(wage>250)~s(year,df=1)+s(age,df=5)+education, family=binomial, data=Wage)
summary(gam6)
par(mfrow=c(1,3))
plot(gam6, se=T, col="orange") # syntax simplified since gam2 is a gam object
# Standard errors at extreme regressor levels seem rather high
#
# Also, no variability of dependent variable at basic education:
table(Wage$education,I(Wage$wage>250))
#
# Let's exclude basic education from the logistic GAM model:
#
gam7 <- gam(I(wage>250)~s(year,df=1)+s(age,df=5)+education, 
            family=binomial, data=Wage,
            subset = (education != "1. < HS Grad"))
summary(gam7)
plot(gam7, se=T, col="orange") 
par(mfrow=c(1,1))
```


---











---


**Self-study based on `{mgcv}` package**

1. Read through chapters 1 & 2 of the online course [GAMS with mgcv package](https://noamross.github.io/gams-in-r-course/)  

2. Re-estimate the above examples using `{mgcv}` package.  

3. Check concurvity (generalization of multicollinearity to smooth functions)  
```{r}
library(mgcv)


```

---